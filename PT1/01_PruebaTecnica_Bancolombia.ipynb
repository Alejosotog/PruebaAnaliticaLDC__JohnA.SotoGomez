{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alejosotog/PruebaAnaliticaLDC__JohnA.SotoGomez/blob/main/PT1/01_PruebaTecnica_Bancolombia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip install MiniBatchKMeans\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib\")\n",
        "\n",
        "# üìÇ Obtener la ruta del directorio donde est√° el notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = \"/content/drive/MyDrive/PruebaTecnica_Bancolombia\""
      ],
      "metadata": {
        "id": "WQQMWwFjUd_r",
        "outputId": "78d42735-0fef-4d66-af3e-7bd40769471e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement MiniBatchKMeans (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for MiniBatchKMeans\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìë Lista de archivos CSV\n",
        "file_list = [\"db_file1.csv\", \"db_file2.csv\", \"db_file3.csv\", \"db_file4.csv\", \"db_file5.csv\"]\n",
        "\n",
        "# üì• Cargar datos en lotes para reducir uso de memoria\n",
        "df_list = [pd.read_csv(os.path.join(folder_path, file), low_memory=False) for file in file_list]\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(f\"Datos cargados correctamente con {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
        "\n",
        "del df_list  # Liberar memoria\n",
        "\n",
        "# üîç Eliminar duplicados\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# üõ†Ô∏è Manejo de valores nulos\n",
        "df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# üéØ Selecci√≥n de variables categ√≥ricas\n",
        "cat_vars = ['tipo_cli', 'estado_cli', 'nivel_academico', 'profn', 'ocup', 'tipo_contrato',\n",
        "            'genero_cli', 'tipo_vivienda', 'pais_nacim', 'origen_fondos', 'operac_moneda_extranjera',\n",
        "            'ciiu', 'nivel_riesgo_ciiu', 'sociedad_ccial_civ', 'mun_res', 'trn_desc_tip_cta', 'trn_oper', 'trn_efec',\n",
        "            'trn_canal_serv_efec']\n",
        "\n",
        "# Verificar si todas las variables categ√≥ricas est√°n en el DataFrame\n",
        "cat_vars = [col for col in cat_vars if col in df.columns]\n",
        "\n",
        "# üîπ Reducir categor√≠as con m√°s de 100 valores (para evitar explosi√≥n de dimensiones)\n",
        "max_categorias = 100\n",
        "for col in cat_vars:\n",
        "    top_categorias = df[col].value_counts().nlargest(max_categorias).index\n",
        "    df[col] = np.where(df[col].isin(top_categorias), df[col], \"Otros\")\n",
        "\n",
        "# üî• Codificaci√≥n eficiente con Target Encoding\n",
        "encoder = ce.TargetEncoder(cols=cat_vars)\n",
        "df[cat_vars] = encoder.fit_transform(df[cat_vars], df['trn_monto'])  # 'trn_monto' como target num√©rico\n",
        "\n",
        "# üîÑ Guardar el encoder para futuros usos\n",
        "joblib.dump(encoder, os.path.join(folder_path, \"target_encoder.pkl\"))\n",
        "\n",
        "# üìä Escalado de variables num√©ricas\n",
        "num_vars = ['ing_mes', 'egresos_mes', 'trn_monto', 'score_riesgo_mun']\n",
        "num_vars = [col for col in num_vars if col in df.columns]  # Verificar existencia\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
        "\n",
        "# üìÇ Guardar el scaler para futuras predicciones\n",
        "joblib.dump(scaler, os.path.join(folder_path, \"scaler.pkl\"))\n",
        "\n",
        "# üìù Procesamiento en lotes y guardado en archivos Parquet para evitar saturaci√≥n de memoria\n",
        "output_folder = os.path.join(folder_path, \"processed_batches\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "batch_size = 10000\n",
        "num_batches = len(df) // batch_size + 1\n",
        "\n",
        "print(f\"Procesando {num_batches} lotes de {batch_size} filas...\")\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i+batch_size]\n",
        "    batch.to_parquet(os.path.join(output_folder, f\"batch_{i//batch_size}.parquet\"))\n",
        "\n",
        "print(\"‚úÖ Preprocesamiento finalizado y datos guardados en Parquet.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEhNptIJmyqH",
        "outputId": "f4534463-76aa-4ce2-e438-af592cd15199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement MiniBatchKMeans (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for MiniBatchKMeans\u001b[0m\u001b[31m\n",
            "\u001b[0mDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Datos cargados correctamente con 4885312 filas y 24 columnas.\n",
            "Procesando 478 lotes de 10000 filas...\n",
            "‚úÖ Preprocesamiento finalizado y datos guardados en Parquet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üõ†Ô∏è Muestreo: tomar 500,000 filas aleatorias para mejorar la velocidad\n",
        "df_sample = df.sample(n=500_000, random_state=42)\n",
        "\n",
        "# üîÑ Llenar valores nulos con la mediana\n",
        "df_sample.fillna(df_sample.median(), inplace=True)\n",
        "\n",
        "# üìè Estandarizar datos\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_sample)"
      ],
      "metadata": {
        "id": "Bpzo749vIiN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä MiniBatchKMeans optimizado\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 4)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = MiniBatchKMeans(\n",
        "        n_clusters=k,\n",
        "        random_state=42,\n",
        "        batch_size=10_000,  # Mini-lotes m√°s grandes para mayor velocidad\n",
        "        n_init=5,           # Reducir inicializaciones\n",
        "        max_iter=50         # Limitar iteraciones\n",
        "    )\n",
        "    labels = kmeans.fit_predict(df_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(df_scaled, labels))\n",
        "\n",
        "print(\"Inertia:\", inertia)\n",
        "print(\"Silhouette Scores:\", silhouette_scores)\n",
        "\n",
        "# üìâ Gr√°ficos del m√©todo del codo y silhouette score\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(K_range, inertia, marker='o')\n",
        "plt.xlabel('N√∫mero de Clusters')\n",
        "plt.ylabel('Inercia')\n",
        "plt.title('Elbow Method')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(K_range, silhouette_scores, marker='o')\n",
        "plt.xlabel('N√∫mero de Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YzOT0KE1EUok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}